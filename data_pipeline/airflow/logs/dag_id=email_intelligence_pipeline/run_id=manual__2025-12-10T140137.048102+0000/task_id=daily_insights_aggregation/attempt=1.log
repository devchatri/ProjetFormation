[2025-12-10T15:02:45.430+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: email_intelligence_pipeline.daily_insights_aggregation manual__2025-12-10T14:01:37.048102+00:00 [queued]>
[2025-12-10T15:02:45.439+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: email_intelligence_pipeline.daily_insights_aggregation manual__2025-12-10T14:01:37.048102+00:00 [queued]>
[2025-12-10T15:02:45.441+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-12-10T15:02:45.461+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): daily_insights_aggregation> on 2025-12-10 14:01:37.048102+00:00
[2025-12-10T15:02:45.467+0000] {standard_task_runner.py:60} INFO - Started process 550 to run task
[2025-12-10T15:02:45.470+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'email_intelligence_pipeline', 'daily_insights_aggregation', 'manual__2025-12-10T14:01:37.048102+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/email_pipeline_dag.py', '--cfg-path', '/tmp/tmpybpwaoup']
[2025-12-10T15:02:45.472+0000] {standard_task_runner.py:88} INFO - Job 48: Subtask daily_insights_aggregation
[2025-12-10T15:02:45.555+0000] {task_command.py:423} INFO - Running <TaskInstance: email_intelligence_pipeline.daily_insights_aggregation manual__2025-12-10T14:01:37.048102+00:00 [running]> on host 2be59bfabb7a
[2025-12-10T15:02:45.646+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data_team' AIRFLOW_CTX_DAG_ID='email_intelligence_pipeline' AIRFLOW_CTX_TASK_ID='daily_insights_aggregation' AIRFLOW_CTX_EXECUTION_DATE='2025-12-10T14:01:37.048102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-12-10T14:01:37.048102+00:00'
[2025-12-10T15:02:45.648+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-10T15:02:45.649+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n        # V√©rifier si quality check a vraiment pass√©\n        QUALITY_REPORT="/tmp/quality_report.json"\n        \n        if [ ! -f "$QUALITY_REPORT" ]; then\n            echo "‚ùå Quality report not found!"\n            exit 1\n        fi\n        \n        # Extraire le score du rapport JSON\n        QUALITY_SCORE=$(grep -o \'"overall_score": [0-9.]*\' "$QUALITY_REPORT" | grep -o \'[0-9.]*\')\n        THRESHOLD=95\n        \n        if (( $(echo "$QUALITY_SCORE < $THRESHOLD" | bc -l) )); then\n            echo "‚ùå Quality score ($QUALITY_SCORE%) is below threshold ($THRESHOLD%)"\n            echo "‚õî Skipping daily aggregation"\n            exit 1\n        fi\n        \n        echo "‚úÖ Quality score ($QUALITY_SCORE%) is above threshold - Running aggregation"\n        /opt/spark/bin/spark-submit --master local[2] --packages org.apache.hadoop:hadoop-aws:3.3.4             --name DailyInsightsAggregation /opt/spark/jobs/daily_aggregation.py\n        ']
[2025-12-10T15:02:45.660+0000] {subprocess.py:86} INFO - Output:
[2025-12-10T15:02:45.672+0000] {subprocess.py:93} INFO - /usr/bin/bash: line 14: bc: command not found
[2025-12-10T15:02:45.673+0000] {subprocess.py:93} INFO - ‚úÖ Quality score (100.0%) is above threshold - Running aggregation
[2025-12-10T15:02:45.690+0000] {subprocess.py:93} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-12-10T15:02:48.406+0000] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-12-10T15:02:48.506+0000] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2025-12-10T15:02:48.507+0000] {subprocess.py:93} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2025-12-10T15:02:48.509+0000] {subprocess.py:93} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2025-12-10T15:02:48.510+0000] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-9baa8279-a163-4c60-ba72-37737200d739;1.0
[2025-12-10T15:02:48.510+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-12-10T15:02:48.702+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-aws;3.3.4 in central
[2025-12-10T15:02:48.737+0000] {subprocess.py:93} INFO - 	found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2025-12-10T15:02:48.767+0000] {subprocess.py:93} INFO - 	found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2025-12-10T15:02:48.784+0000] {subprocess.py:93} INFO - :: resolution report :: resolve 265ms :: artifacts dl 9ms
[2025-12-10T15:02:48.785+0000] {subprocess.py:93} INFO - 	:: modules in use:
[2025-12-10T15:02:48.786+0000] {subprocess.py:93} INFO - 	com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2025-12-10T15:02:48.786+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]
[2025-12-10T15:02:48.787+0000] {subprocess.py:93} INFO - 	org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2025-12-10T15:02:48.788+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-12-10T15:02:48.788+0000] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-12-10T15:02:48.789+0000] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-12-10T15:02:48.790+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-12-10T15:02:48.790+0000] {subprocess.py:93} INFO - 	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
[2025-12-10T15:02:48.791+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-12-10T15:02:48.792+0000] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-9baa8279-a163-4c60-ba72-37737200d739
[2025-12-10T15:02:48.792+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-12-10T15:02:48.793+0000] {subprocess.py:93} INFO - 	0 artifacts copied, 3 already retrieved (0kB/4ms)
[2025-12-10T15:02:49.051+0000] {subprocess.py:93} INFO - 25/12/10 15:02:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-12-10T15:02:50.080+0000] {subprocess.py:93} INFO - ============================================================
[2025-12-10T15:02:50.081+0000] {subprocess.py:93} INFO - üöÄ DAILY AGGREGATION JOB STARTED
[2025-12-10T15:02:50.083+0000] {subprocess.py:93} INFO -    Timestamp: 2025-12-10 15:02:50.080055
[2025-12-10T15:02:50.084+0000] {subprocess.py:93} INFO - ============================================================
[2025-12-10T15:02:50.241+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkContext: Running Spark version 3.5.0
[2025-12-10T15:02:50.242+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-12-10T15:02:50.243+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkContext: Java version 17.0.17
[2025-12-10T15:02:50.264+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceUtils: ==============================================================
[2025-12-10T15:02:50.266+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-12-10T15:02:50.267+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceUtils: ==============================================================
[2025-12-10T15:02:50.267+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkContext: Submitted application: DailyAggregation
[2025-12-10T15:02:50.298+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-12-10T15:02:50.309+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceProfile: Limiting resource is cpu
[2025-12-10T15:02:50.310+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-12-10T15:02:50.392+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SecurityManager: Changing view acls to: ***
[2025-12-10T15:02:50.393+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SecurityManager: Changing modify acls to: ***
[2025-12-10T15:02:50.393+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SecurityManager: Changing view acls groups to:
[2025-12-10T15:02:50.394+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SecurityManager: Changing modify acls groups to:
[2025-12-10T15:02:50.395+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-12-10T15:02:50.654+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO Utils: Successfully started service 'sparkDriver' on port 37837.
[2025-12-10T15:02:50.710+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkEnv: Registering MapOutputTracker
[2025-12-10T15:02:50.751+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkEnv: Registering BlockManagerMaster
[2025-12-10T15:02:50.776+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-12-10T15:02:50.777+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-12-10T15:02:50.786+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-12-10T15:02:50.811+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2f16e38a-3186-4425-b1fe-827db9ad5295
[2025-12-10T15:02:50.825+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-12-10T15:02:50.841+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-12-10T15:02:50.984+0000] {subprocess.py:93} INFO - 25/12/10 15:02:50 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-12-10T15:02:51.052+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-12-10T15:02:51.119+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://2be59bfabb7a:37837/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1765378970234
[2025-12-10T15:02:51.122+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://2be59bfabb7a:37837/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1765378970234
[2025-12-10T15:02:51.122+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://2be59bfabb7a:37837/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1765378970234
[2025-12-10T15:02:51.123+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1765378970234
[2025-12-10T15:02:51.125+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-12-10T15:02:51.141+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1765378970234
[2025-12-10T15:02:51.142+0000] {subprocess.py:93} INFO - 25/12/10 15:02:51 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-12-10T15:02:52.304+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1765378970234
[2025-12-10T15:02:52.305+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: Copying /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-12-10T15:02:52.361+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Starting executor ID driver on host 2be59bfabb7a
[2025-12-10T15:02:52.362+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-12-10T15:02:52.366+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Java version 17.0.17
[2025-12-10T15:02:52.370+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-12-10T15:02:52.371+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6236a131 for default.
[2025-12-10T15:02:52.381+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Fetching file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1765378970234
[2025-12-10T15:02:52.529+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-12-10T15:02:52.558+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1765378970234
[2025-12-10T15:02:52.559+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-12-10T15:02:52.578+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1765378970234
[2025-12-10T15:02:52.580+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-12-10T15:02:52.649+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Fetching spark://2be59bfabb7a:37837/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1765378970234
[2025-12-10T15:02:52.730+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO TransportClientFactory: Successfully created connection to 2be59bfabb7a/172.19.0.9:37837 after 65 ms (0 ms spent in bootstraps)
[2025-12-10T15:02:52.741+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: Fetching spark://2be59bfabb7a:37837/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp12182877042146183023.tmp
[2025-12-10T15:02:52.870+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp12182877042146183023.tmp has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-12-10T15:02:52.892+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Adding file:/tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to class loader default
[2025-12-10T15:02:52.893+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Executor: Fetching spark://2be59bfabb7a:37837/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1765378970234
[2025-12-10T15:02:52.894+0000] {subprocess.py:93} INFO - 25/12/10 15:02:52 INFO Utils: Fetching spark://2be59bfabb7a:37837/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp6632543661473526227.tmp
[2025-12-10T15:02:56.096+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Utils: /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp6632543661473526227.tmp has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-12-10T15:02:56.155+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Executor: Adding file:/tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to class loader default
[2025-12-10T15:02:56.156+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Executor: Fetching spark://2be59bfabb7a:37837/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1765378970234
[2025-12-10T15:02:56.157+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Utils: Fetching spark://2be59bfabb7a:37837/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp11014309681172541658.tmp
[2025-12-10T15:02:56.190+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Utils: /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/fetchFileTemp11014309681172541658.tmp has been previously copied to /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-12-10T15:02:56.200+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Executor: Adding file:/tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/userFiles-34155db8-a35d-4db6-8d1e-00fb130f4f30/org.apache.hadoop_hadoop-aws-3.3.4.jar to class loader default
[2025-12-10T15:02:56.228+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32819.
[2025-12-10T15:02:56.229+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO NettyBlockTransferService: Server created on 2be59bfabb7a:32819
[2025-12-10T15:02:56.233+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-12-10T15:02:56.250+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2be59bfabb7a, 32819, None)
[2025-12-10T15:02:56.257+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO BlockManagerMasterEndpoint: Registering block manager 2be59bfabb7a:32819 with 434.4 MiB RAM, BlockManagerId(driver, 2be59bfabb7a, 32819, None)
[2025-12-10T15:02:56.259+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2be59bfabb7a, 32819, None)
[2025-12-10T15:02:56.265+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2be59bfabb7a, 32819, None)
[2025-12-10T15:02:56.920+0000] {subprocess.py:93} INFO - üìå Step 1: Reading Bronze layer from MinIO...
[2025-12-10T15:02:56.928+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-12-10T15:02:56.930+0000] {subprocess.py:93} INFO - 25/12/10 15:02:56 INFO SharedState: Warehouse path is 'file:/tmp/***tmpy0x3zo6h/spark-warehouse'.
[2025-12-10T15:02:57.779+0000] {subprocess.py:93} INFO - 25/12/10 15:02:57 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-12-10T15:02:57.795+0000] {subprocess.py:93} INFO - 25/12/10 15:02:57 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-12-10T15:02:57.800+0000] {subprocess.py:93} INFO - 25/12/10 15:02:57 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-12-10T15:02:58.733+0000] {subprocess.py:93} INFO - 25/12/10 15:02:58 INFO MetadataLogFileIndex: Reading streaming file log from s3a://datalake/bronze/emails/_spark_metadata
[2025-12-10T15:02:58.800+0000] {subprocess.py:93} INFO - 25/12/10 15:02:58 INFO FileStreamSinkLog: BatchIds found from listing: 0
[2025-12-10T15:02:58.820+0000] {subprocess.py:93} INFO - 25/12/10 15:02:58 INFO FileStreamSinkLog: Set the compact interval to 10 [defaultCompactInterval: 10]
[2025-12-10T15:02:58.828+0000] {subprocess.py:93} INFO - 25/12/10 15:02:58 INFO deprecation: org.apache.hadoop.shaded.io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[2025-12-10T15:02:59.278+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-12-10T15:02:59.293+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:02:59.298+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:02:59.299+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:02:59.300+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:02:59.301+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:02:59.380+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 105.5 KiB, free 434.3 MiB)
[2025-12-10T15:02:59.405+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.2 KiB, free 434.3 MiB)
[2025-12-10T15:02:59.407+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 2be59bfabb7a:32819 (size: 38.2 KiB, free: 434.4 MiB)
[2025-12-10T15:02:59.410+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:02:59.423+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:02:59.426+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-12-10T15:02:59.463+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8496 bytes)
[2025-12-10T15:02:59.479+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-12-10T15:02:59.648+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:02:59.841+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2212 bytes result sent to driver
[2025-12-10T15:02:59.853+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 404 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:02:59.855+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-12-10T15:02:59.860+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.546 s
[2025-12-10T15:02:59.861+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:02:59.862+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-12-10T15:02:59.865+0000] {subprocess.py:93} INFO - 25/12/10 15:02:59 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.587259 s
[2025-12-10T15:03:00.870+0000] {subprocess.py:93} INFO - 25/12/10 15:03:00 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:00.871+0000] {subprocess.py:93} INFO - 25/12/10 15:03:00 INFO FileSourceStrategy: Post-Scan Filters:
[2025-12-10T15:03:01.275+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO CodeGenerator: Code generated in 176.191334 ms
[2025-12-10T15:03:01.298+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 204.5 KiB, free 434.1 MiB)
[2025-12-10T15:03:01.310+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 434.0 MiB)
[2025-12-10T15:03:01.312+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 2be59bfabb7a:32819 (size: 35.6 KiB, free: 434.3 MiB)
[2025-12-10T15:03:01.314+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:01.334+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:01.381+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-12-10T15:03:01.387+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:01.388+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:01.389+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:01.389+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:01.390+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:01.429+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 16.8 KiB, free 434.0 MiB)
[2025-12-10T15:03:01.431+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.0 MiB)
[2025-12-10T15:03:01.432+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 2be59bfabb7a:32819 (size: 7.7 KiB, free: 434.3 MiB)
[2025-12-10T15:03:01.432+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:01.434+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:01.435+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-12-10T15:03:01.439+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:01.441+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-12-10T15:03:01.547+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO CodeGenerator: Code generated in 65.799462 ms
[2025-12-10T15:03:01.562+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:01.564+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 2be59bfabb7a:32819 in memory (size: 38.2 KiB, free: 434.4 MiB)
[2025-12-10T15:03:01.585+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:01.696+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2222 bytes result sent to driver
[2025-12-10T15:03:01.699+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 263 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:01.700+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-12-10T15:03:01.703+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.308 s
[2025-12-10T15:03:01.705+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:01.706+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:01.707+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:01.708+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:01.749+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO CodeGenerator: Code generated in 11.985161 ms
[2025-12-10T15:03:01.768+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:01.771+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:01.772+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:01.773+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-12-10T15:03:01.774+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:01.775+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:01.781+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-12-10T15:03:01.783+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-12-10T15:03:01.784+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 2be59bfabb7a:32819 (size: 5.9 KiB, free: 434.4 MiB)
[2025-12-10T15:03:01.786+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:01.787+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:01.788+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-12-10T15:03:01.792+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:01.793+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
[2025-12-10T15:03:01.832+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:01.834+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-12-10T15:03:01.847+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO CodeGenerator: Code generated in 8.805458 ms
[2025-12-10T15:03:01.859+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 4038 bytes result sent to driver
[2025-12-10T15:03:01.862+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 71 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:01.863+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-12-10T15:03:01.864+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.085 s
[2025-12-10T15:03:01.866+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:01.867+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-12-10T15:03:01.868+0000] {subprocess.py:93} INFO - 25/12/10 15:03:01 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.096917 s
[2025-12-10T15:03:01.872+0000] {subprocess.py:93} INFO - ‚úÖ Bronze layer loaded successfully: 27 records
[2025-12-10T15:03:01.874+0000] {subprocess.py:93} INFO - üìå Step 2: Creating daily aggregations...
[2025-12-10T15:03:01.940+0000] {subprocess.py:93} INFO -    ‚Ä¢ Calculating total emails per day...
[2025-12-10T15:03:02.001+0000] {subprocess.py:93} INFO -    ‚Ä¢ Calculating top 10 sender domains...
[2025-12-10T15:03:02.219+0000] {subprocess.py:93} INFO -    ‚Ä¢ Calculating busiest hour...
[2025-12-10T15:03:02.310+0000] {subprocess.py:93} INFO -    ‚Ä¢ Combining all aggregations...
[2025-12-10T15:03:02.557+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 2be59bfabb7a:32819 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-12-10T15:03:02.566+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:02.567+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO FileSourceStrategy: Post-Scan Filters:
[2025-12-10T15:03:02.570+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 2be59bfabb7a:32819 in memory (size: 7.7 KiB, free: 434.4 MiB)
[2025-12-10T15:03:02.581+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:02.582+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#166 as date))
[2025-12-10T15:03:02.760+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO CodeGenerator: Code generated in 75.299422 ms
[2025-12-10T15:03:02.770+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 204.6 KiB, free 434.0 MiB)
[2025-12-10T15:03:02.784+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 433.9 MiB)
[2025-12-10T15:03:02.791+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:02.792+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:02.794+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:02.836+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 2be59bfabb7a:32819 in memory (size: 35.6 KiB, free: 434.4 MiB)
[2025-12-10T15:03:02.879+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Registering RDD 12 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-12-10T15:03:02.880+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:02.882+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:02.883+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:02.885+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:02.886+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:02.889+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 434.1 MiB)
[2025-12-10T15:03:02.894+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 434.1 MiB)
[2025-12-10T15:03:02.896+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 2be59bfabb7a:32819 (size: 17.1 KiB, free: 434.3 MiB)
[2025-12-10T15:03:02.902+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:02.906+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:02.907+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-12-10T15:03:02.909+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:02.910+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
[2025-12-10T15:03:02.981+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO CodeGenerator: Code generated in 58.360332 ms
[2025-12-10T15:03:02.982+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO CodeGenerator: Code generated in 56.832951 ms
[2025-12-10T15:03:02.988+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 204.6 KiB, free 433.9 MiB)
[2025-12-10T15:03:02.998+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 433.9 MiB)
[2025-12-10T15:03:03.000+0000] {subprocess.py:93} INFO - 25/12/10 15:03:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:03.001+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:03.006+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:03.018+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 18.275447 ms
[2025-12-10T15:03:03.034+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 8.198448 ms
[2025-12-10T15:03:03.042+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-12-10T15:03:03.044+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:03.051+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:03.052+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:03.055+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:03.056+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:03.058+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 44.3 KiB, free 425.8 MiB)
[2025-12-10T15:03:03.059+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 425.8 MiB)
[2025-12-10T15:03:03.060+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 2be59bfabb7a:32819 (size: 19.6 KiB, free: 434.3 MiB)
[2025-12-10T15:03:03.061+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:03.063+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 10.295471 ms
[2025-12-10T15:03:03.064+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:03.065+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-12-10T15:03:03.066+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:03.067+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
[2025-12-10T15:03:03.068+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:03.092+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:03.140+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 59.554464 ms
[2025-12-10T15:03:03.154+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 9.28147 ms
[2025-12-10T15:03:03.166+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 5.632528 ms
[2025-12-10T15:03:03.186+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 11.964889 ms
[2025-12-10T15:03:03.191+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-12-10T15:03:03.198+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 5.02218 ms
[2025-12-10T15:03:03.204+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:03.223+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:03.255+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-12-10T15:03:03.367+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 3016 bytes result sent to driver
[2025-12-10T15:03:03.370+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 3029 bytes result sent to driver
[2025-12-10T15:03:03.372+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 470 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:03.375+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-12-10T15:03:03.377+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 314 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:03.378+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-12-10T15:03:03.379+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.494 s
[2025-12-10T15:03:03.381+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:03.383+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
[2025-12-10T15:03:03.384+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:03.386+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:03.388+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.334 s
[2025-12-10T15:03:03.390+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:03.391+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:03.392+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:03.392+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:03.430+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:03.464+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:03.496+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 22.03715 ms
[2025-12-10T15:03:03.516+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-12-10T15:03:03.518+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:03.520+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:03.522+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-12-10T15:03:03.524+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:03.525+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:03.569+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 48.5 KiB, free 433.8 MiB)
[2025-12-10T15:03:03.575+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)
[2025-12-10T15:03:03.577+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 2be59bfabb7a:32819 (size: 21.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:03.578+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:03.580+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:03.581+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-12-10T15:03:03.584+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:03.587+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
[2025-12-10T15:03:03.622+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO ShuffleBlockFetcherIterator: Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:03.624+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-12-10T15:03:03.678+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 53.83471 ms
[2025-12-10T15:03:03.738+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 38.113731 ms
[2025-12-10T15:03:03.788+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 16.935282 ms
[2025-12-10T15:03:03.836+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 5.845452 ms
[2025-12-10T15:03:03.850+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 5962 bytes result sent to driver
[2025-12-10T15:03:03.853+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 269 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:03.854+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-12-10T15:03:03.855+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.329 s
[2025-12-10T15:03:03.856+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:03.856+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:03.857+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:03.858+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:03.870+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:03.910+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 9.360471 ms
[2025-12-10T15:03:03.928+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO CodeGenerator: Code generated in 10.997358 ms
[2025-12-10T15:03:03.974+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:03.975+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:03.976+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:03.977+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
[2025-12-10T15:03:03.978+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:03.979+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:03.981+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 52.5 KiB, free 433.7 MiB)
[2025-12-10T15:03:03.983+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 433.7 MiB)
[2025-12-10T15:03:03.984+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 2be59bfabb7a:32819 (size: 23.5 KiB, free: 434.2 MiB)
[2025-12-10T15:03:03.985+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:03.986+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:03.987+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-12-10T15:03:03.989+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:03.991+0000] {subprocess.py:93} INFO - 25/12/10 15:03:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 6)
[2025-12-10T15:03:04.005+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 2be59bfabb7a:32819 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.016+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Getting 1 (146.0 B) non-empty blocks including 1 (146.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:04.018+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:04.025+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 7.684523 ms
[2025-12-10T15:03:04.045+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 5.469804 ms
[2025-12-10T15:03:04.073+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 6.992775 ms
[2025-12-10T15:03:04.090+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 6.891891 ms
[2025-12-10T15:03:04.098+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 4.983083 ms
[2025-12-10T15:03:04.113+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 12.885922 ms
[2025-12-10T15:03:04.127+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Finished task 0.0 in stage 10.0 (TID 6). 7347 bytes result sent to driver
[2025-12-10T15:03:04.130+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 141 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:04.132+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-12-10T15:03:04.134+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.154 s
[2025-12-10T15:03:04.139+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:04.140+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
[2025-12-10T15:03:04.142+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.160523 s
[2025-12-10T15:03:04.167+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 15.461214 ms
[2025-12-10T15:03:04.168+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 2be59bfabb7a:32819 in memory (size: 17.1 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.177+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.0 MiB, free 425.8 MiB)
[2025-12-10T15:03:04.183+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 2be59bfabb7a:32819 in memory (size: 19.6 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.185+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 175.0 B, free 425.8 MiB)
[2025-12-10T15:03:04.187+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 2be59bfabb7a:32819 (size: 175.0 B, free: 434.3 MiB)
[2025-12-10T15:03:04.189+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:04.197+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:04.245+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 23.611135 ms
[2025-12-10T15:03:04.266+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Registering RDD 29 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-12-10T15:03:04.267+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:04.268+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:04.269+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
[2025-12-10T15:03:04.269+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:04.272+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:04.279+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 72.7 KiB, free 425.8 MiB)
[2025-12-10T15:03:04.282+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 425.8 MiB)
[2025-12-10T15:03:04.283+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 2be59bfabb7a:32819 (size: 31.1 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.284+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:04.285+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:04.285+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-12-10T15:03:04.287+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:04.295+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Running task 0.0 in stage 12.0 (TID 7)
[2025-12-10T15:03:04.312+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Getting 1 (120.0 B) non-empty blocks including 1 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:04.313+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:04.330+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 17.050249 ms
[2025-12-10T15:03:04.342+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 7). 10577 bytes result sent to driver
[2025-12-10T15:03:04.344+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 58 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:04.345+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-12-10T15:03:04.345+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.072 s
[2025-12-10T15:03:04.346+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:04.348+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:04.349+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:04.350+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:04.365+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 3.919444 ms
[2025-12-10T15:03:04.376+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:04.377+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:04.378+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:04.378+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2025-12-10T15:03:04.379+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:04.380+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[32] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:04.381+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.5 KiB, free 425.7 MiB)
[2025-12-10T15:03:04.381+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.7 MiB)
[2025-12-10T15:03:04.382+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 2be59bfabb7a:32819 (size: 5.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.383+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:04.384+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[32] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:04.384+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-12-10T15:03:04.385+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 8) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:04.386+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Running task 0.0 in stage 15.0 (TID 8)
[2025-12-10T15:03:04.391+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:04.393+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:04.396+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 3.700742 ms
[2025-12-10T15:03:04.399+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Finished task 0.0 in stage 15.0 (TID 8). 3995 bytes result sent to driver
[2025-12-10T15:03:04.400+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 8) in 16 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:04.401+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-12-10T15:03:04.401+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s
[2025-12-10T15:03:04.402+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:04.404+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-12-10T15:03:04.406+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.025767 s
[2025-12-10T15:03:04.409+0000] {subprocess.py:93} INFO - ‚úÖ Daily aggregations created successfully: 2 records
[2025-12-10T15:03:04.513+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:04.514+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-12-10T15:03:04.516+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:04.518+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#148 as date))
[2025-12-10T15:03:04.519+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:04.520+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#166 as date))
[2025-12-10T15:03:04.660+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 25.704112 ms
[2025-12-10T15:03:04.665+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 204.6 KiB, free 425.5 MiB)
[2025-12-10T15:03:04.673+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 425.5 MiB)
[2025-12-10T15:03:04.675+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:04.676+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:04.678+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:04.696+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 2be59bfabb7a:32819 in memory (size: 31.1 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.701+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Registering RDD 36 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-12-10T15:03:04.704+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Got map stage job 9 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:04.708+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:04.711+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:04.713+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:04.715+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[36] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:04.716+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 40.2 KiB, free 425.6 MiB)
[2025-12-10T15:03:04.717+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 2be59bfabb7a:32819 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.720+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 425.6 MiB)
[2025-12-10T15:03:04.726+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 2be59bfabb7a:32819 (size: 18.3 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.728+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:04.729+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[36] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:04.730+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-12-10T15:03:04.731+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 9) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:04.732+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Running task 0.0 in stage 16.0 (TID 9)
[2025-12-10T15:03:04.763+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 44.83066 ms
[2025-12-10T15:03:04.765+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO CodeGenerator: Code generated in 31.215639 ms
[2025-12-10T15:03:04.766+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 204.8 KiB, free 425.4 MiB)
[2025-12-10T15:03:04.799+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 417.1 MiB)
[2025-12-10T15:03:04.807+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:04.808+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 2be59bfabb7a:32819 (size: 36.0 KiB, free: 434.2 MiB)
[2025-12-10T15:03:04.810+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 15 from showString at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:04.811+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:04.832+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.845+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Registering RDD 40 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-12-10T15:03:04.847+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Got map stage job 10 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:04.850+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:04.852+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:04.857+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:04.858+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:04.860+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[40] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:04.861+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 43.3 KiB, free 417.3 MiB)
[2025-12-10T15:03:04.868+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 417.3 MiB)
[2025-12-10T15:03:04.874+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 2be59bfabb7a:32819 in memory (size: 23.5 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.876+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 2be59bfabb7a:32819 (size: 19.3 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.878+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:04.879+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[40] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:04.880+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-12-10T15:03:04.882+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:04.885+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Running task 0.0 in stage 17.0 (TID 10)
[2025-12-10T15:03:04.890+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:04.913+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 2be59bfabb7a:32819 in memory (size: 175.0 B, free: 434.3 MiB)
[2025-12-10T15:03:04.978+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO Executor: Finished task 0.0 in stage 16.0 (TID 9). 3016 bytes result sent to driver
[2025-12-10T15:03:04.982+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 9) in 253 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:04.985+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-12-10T15:03:04.993+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: ShuffleMapStage 16 (showString at NativeMethodAccessorImpl.java:0) finished in 0.277 s
[2025-12-10T15:03:05.001+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:05.004+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: running: Set(ShuffleMapStage 17)
[2025-12-10T15:03:05.008+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:05.009+0000] {subprocess.py:93} INFO - 25/12/10 15:03:04 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:05.045+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 135.769046 ms
[2025-12-10T15:03:05.048+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 131.70441 ms
[2025-12-10T15:03:05.062+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 204.6 KiB, free 433.6 MiB)
[2025-12-10T15:03:05.093+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 433.6 MiB)
[2025-12-10T15:03:05.095+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:05.098+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO SparkContext: Created broadcast 17 from showString at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:05.100+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 34.019199 ms
[2025-12-10T15:03:05.102+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:05.126+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Registering RDD 44 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-12-10T15:03:05.127+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Got map stage job 11 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:05.131+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:05.133+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:05.134+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:05.135+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:05.137+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 44.4 KiB, free 425.5 MiB)
[2025-12-10T15:03:05.140+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 425.5 MiB)
[2025-12-10T15:03:05.142+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 2be59bfabb7a:32819 (size: 19.7 KiB, free: 434.2 MiB)
[2025-12-10T15:03:05.144+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:05.146+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:05.147+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-12-10T15:03:05.151+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 11) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:05.154+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 25.059703 ms
[2025-12-10T15:03:05.155+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Running task 0.0 in stage 18.0 (TID 11)
[2025-12-10T15:03:05.173+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:05.217+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:05.285+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 103.619348 ms
[2025-12-10T15:03:05.314+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:05.318+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Finished task 0.0 in stage 17.0 (TID 10). 2986 bytes result sent to driver
[2025-12-10T15:03:05.322+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 442 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:05.328+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-12-10T15:03:05.330+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: ShuffleMapStage 17 (showString at NativeMethodAccessorImpl.java:0) finished in 0.476 s
[2025-12-10T15:03:05.332+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:05.334+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: running: Set(ShuffleMapStage 18)
[2025-12-10T15:03:05.335+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:05.335+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:05.345+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:05.378+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:05.463+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Finished task 0.0 in stage 18.0 (TID 11). 3029 bytes result sent to driver
[2025-12-10T15:03:05.468+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 11) in 318 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:05.472+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-12-10T15:03:05.475+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 0.339 s
[2025-12-10T15:03:05.479+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:05.481+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:05.482+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:05.484+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:05.485+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:05.547+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 49.032288 ms
[2025-12-10T15:03:05.565+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Registering RDD 48 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-12-10T15:03:05.566+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Got map stage job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:05.567+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:05.568+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-12-10T15:03:05.569+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:05.569+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[48] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:05.582+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 47.6 KiB, free 433.5 MiB)
[2025-12-10T15:03:05.585+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 433.4 MiB)
[2025-12-10T15:03:05.590+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 2be59bfabb7a:32819 (size: 21.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:05.592+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:05.593+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[48] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:05.594+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-12-10T15:03:05.595+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 12) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:05.596+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Running task 0.0 in stage 20.0 (TID 12)
[2025-12-10T15:03:05.615+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:05.622+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:05.624+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-12-10T15:03:05.678+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:05.680+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 56.045917 ms
[2025-12-10T15:03:05.699+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 13.581893 ms
[2025-12-10T15:03:05.732+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 41.482592 ms
[2025-12-10T15:03:05.743+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 12.571793 ms
[2025-12-10T15:03:05.747+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Registering RDD 52 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-12-10T15:03:05.755+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Got map stage job 13 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:05.757+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:05.758+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-12-10T15:03:05.759+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:05.761+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[52] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:05.762+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 48.9 KiB, free 425.3 MiB)
[2025-12-10T15:03:05.764+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 425.3 MiB)
[2025-12-10T15:03:05.765+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 2be59bfabb7a:32819 (size: 22.0 KiB, free: 434.2 MiB)
[2025-12-10T15:03:05.766+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:05.767+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[52] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:05.768+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-12-10T15:03:05.773+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 13) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:05.775+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Running task 0.0 in stage 22.0 (TID 13)
[2025-12-10T15:03:05.778+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO Executor: Finished task 0.0 in stage 20.0 (TID 12). 6005 bytes result sent to driver
[2025-12-10T15:03:05.782+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 12) in 187 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:05.784+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-12-10T15:03:05.785+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: ShuffleMapStage 20 (showString at NativeMethodAccessorImpl.java:0) finished in 0.210 s
[2025-12-10T15:03:05.790+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:05.792+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: running: Set(ShuffleMapStage 22)
[2025-12-10T15:03:05.793+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:05.795+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:05.811+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShuffleBlockFetcherIterator: Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:05.813+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-12-10T15:03:05.880+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:05.913+0000] {subprocess.py:93} INFO - 25/12/10 15:03:05 INFO CodeGenerator: Code generated in 99.197521 ms
[2025-12-10T15:03:06.007+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Finished task 0.0 in stage 22.0 (TID 13). 5962 bytes result sent to driver
[2025-12-10T15:03:06.010+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 13) in 240 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:06.012+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-12-10T15:03:06.014+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: ShuffleMapStage 22 (showString at NativeMethodAccessorImpl.java:0) finished in 0.260 s
[2025-12-10T15:03:06.015+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:06.017+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:06.019+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:06.023+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:06.049+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:06.062+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 30.631968 ms
[2025-12-10T15:03:06.095+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 27.472006 ms
[2025-12-10T15:03:06.147+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 22.429309 ms
[2025-12-10T15:03:06.167+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 16.470795 ms
[2025-12-10T15:03:06.184+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:06.191+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:06.194+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:06.195+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-12-10T15:03:06.196+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:06.197+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[60] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:06.207+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 56.7 KiB, free 433.3 MiB)
[2025-12-10T15:03:06.210+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 433.3 MiB)
[2025-12-10T15:03:06.211+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 2be59bfabb7a:32819 (size: 25.1 KiB, free: 434.2 MiB)
[2025-12-10T15:03:06.212+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:06.212+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[60] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:06.213+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-12-10T15:03:06.214+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 14) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:06.215+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Running task 0.0 in stage 25.0 (TID 14)
[2025-12-10T15:03:06.224+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:06.225+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:06.226+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Final stage: ResultStage 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:06.227+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
[2025-12-10T15:03:06.228+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:06.228+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:06.231+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 53.2 KiB, free 433.2 MiB)
[2025-12-10T15:03:06.232+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 433.2 MiB)
[2025-12-10T15:03:06.233+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 2be59bfabb7a:32819 (size: 23.7 KiB, free: 434.1 MiB)
[2025-12-10T15:03:06.234+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:06.237+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:06.240+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (325.0 B) non-empty blocks including 1 (325.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:06.240+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-12-10T15:03:06.241+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-12-10T15:03:06.247+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 15) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:06.248+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Running task 0.0 in stage 28.0 (TID 15)
[2025-12-10T15:03:06.263+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 23.084748 ms
[2025-12-10T15:03:06.268+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (160.0 B) non-empty blocks including 1 (160.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:06.270+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-12-10T15:03:06.290+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 20.275932 ms
[2025-12-10T15:03:06.300+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 16.887678 ms
[2025-12-10T15:03:06.329+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 13.377452 ms
[2025-12-10T15:03:06.335+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 10.43921 ms
[2025-12-10T15:03:06.357+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 15.842108 ms
[2025-12-10T15:03:06.360+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 16.17745 ms
[2025-12-10T15:03:06.367+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Finished task 0.0 in stage 28.0 (TID 15). 7323 bytes result sent to driver
[2025-12-10T15:03:06.373+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 15) in 133 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:06.375+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-12-10T15:03:06.376+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: ResultStage 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.148 s
[2025-12-10T15:03:06.378+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:06.379+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
[2025-12-10T15:03:06.380+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.152620 s
[2025-12-10T15:03:06.391+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.0 MiB, free 417.2 MiB)
[2025-12-10T15:03:06.394+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 195.0 B, free 417.2 MiB)
[2025-12-10T15:03:06.396+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 14.175682 ms
[2025-12-10T15:03:06.397+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 2be59bfabb7a:32819 (size: 195.0 B, free: 434.1 MiB)
[2025-12-10T15:03:06.397+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:06.426+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 13.872303 ms
[2025-12-10T15:03:06.482+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 13.566524 ms
[2025-12-10T15:03:06.511+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 16.961213 ms
[2025-12-10T15:03:06.526+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Finished task 0.0 in stage 25.0 (TID 14). 7930 bytes result sent to driver
[2025-12-10T15:03:06.529+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 14) in 316 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:06.531+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-12-10T15:03:06.532+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.334 s
[2025-12-10T15:03:06.533+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:06.535+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
[2025-12-10T15:03:06.536+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.346460 s
[2025-12-10T15:03:06.541+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.0 MiB, free 417.2 MiB)
[2025-12-10T15:03:06.545+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 309.0 B, free 417.2 MiB)
[2025-12-10T15:03:06.546+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 2be59bfabb7a:32819 (size: 309.0 B, free: 434.1 MiB)
[2025-12-10T15:03:06.547+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:06.562+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:06.600+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:06.693+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 54.022517 ms
[2025-12-10T15:03:06.735+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:06.740+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Got job 16 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:06.742+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Final stage: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:06.743+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-12-10T15:03:06.744+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:06.745+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[69] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:06.761+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 98.1 KiB, free 417.1 MiB)
[2025-12-10T15:03:06.763+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 417.1 MiB)
[2025-12-10T15:03:06.764+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 2be59bfabb7a:32819 (size: 39.5 KiB, free: 434.1 MiB)
[2025-12-10T15:03:06.766+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:06.767+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[69] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:06.768+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-12-10T15:03:06.773+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 16) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:06.775+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Running task 0.0 in stage 30.0 (TID 16)
[2025-12-10T15:03:06.796+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (132.0 B) non-empty blocks including 1 (132.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:06.798+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-12-10T15:03:06.836+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO CodeGenerator: Code generated in 38.048408 ms
[2025-12-10T15:03:06.902+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO Executor: Finished task 0.0 in stage 30.0 (TID 16). 15480 bytes result sent to driver
[2025-12-10T15:03:06.931+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 16) in 161 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:06.933+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-12-10T15:03:06.939+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 0.186 s
[2025-12-10T15:03:06.941+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:06.943+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-12-10T15:03:06.945+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 2be59bfabb7a:32819 in memory (size: 25.1 KiB, free: 434.1 MiB)
[2025-12-10T15:03:06.946+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO DAGScheduler: Job 16 finished: showString at NativeMethodAccessorImpl.java:0, took 0.200090 s
[2025-12-10T15:03:06.952+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 2be59bfabb7a:32819 in memory (size: 21.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:06.965+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 2be59bfabb7a:32819 in memory (size: 19.3 KiB, free: 434.2 MiB)
[2025-12-10T15:03:06.981+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 2be59bfabb7a:32819 in memory (size: 22.0 KiB, free: 434.2 MiB)
[2025-12-10T15:03:06.991+0000] {subprocess.py:93} INFO - 25/12/10 15:03:06 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 2be59bfabb7a:32819 in memory (size: 19.7 KiB, free: 434.2 MiB)
[2025-12-10T15:03:07.000+0000] {subprocess.py:93} INFO - 25/12/10 15:03:07 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 2be59bfabb7a:32819 in memory (size: 23.7 KiB, free: 434.2 MiB)
[2025-12-10T15:03:07.014+0000] {subprocess.py:93} INFO - 25/12/10 15:03:07 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 2be59bfabb7a:32819 in memory (size: 18.3 KiB, free: 434.3 MiB)
[2025-12-10T15:03:08.812+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO CodeGenerator: Code generated in 12.566816 ms
[2025-12-10T15:03:08.828+0000] {subprocess.py:93} INFO - +----------+------------+---------------------------------------------------------------------------------------------------------------------------+------------+------------------+
[2025-12-10T15:03:08.829+0000] {subprocess.py:93} INFO - |date      |total_emails|domain_counts                                                                                                              |busiest_hour|busiest_hour_count|
[2025-12-10T15:03:08.831+0000] {subprocess.py:93} INFO - +----------+------------+---------------------------------------------------------------------------------------------------------------------------+------------+------------------+
[2025-12-10T15:03:08.832+0000] {subprocess.py:93} INFO - |2025-12-09|3           |join.netflix.com>:3                                                                                                        |22          |3                 |
[2025-12-10T15:03:08.832+0000] {subprocess.py:93} INFO - |2025-12-10|24          |linkedin.com>:9|marocemploi.net>:3|mail.clickup.com>:3|surveylama.com>:3|eu-shop.temuemail.com>:3|commerce.temuemail.com>:3|13          |9                 |
[2025-12-10T15:03:08.833+0000] {subprocess.py:93} INFO - +----------+------------+---------------------------------------------------------------------------------------------------------------------------+------------+------------------+
[2025-12-10T15:03:08.834+0000] {subprocess.py:93} INFO - 
[2025-12-10T15:03:08.932+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:08.934+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO FileSourceStrategy: Post-Scan Filters:
[2025-12-10T15:03:08.939+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:08.940+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#166 as date))
[2025-12-10T15:03:08.993+0000] {subprocess.py:93} INFO - 25/12/10 15:03:08 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 204.6 KiB, free 417.4 MiB)
[2025-12-10T15:03:09.016+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 417.3 MiB)
[2025-12-10T15:03:09.019+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.023+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 26 from count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.024+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:09.034+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 73 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-12-10T15:03:09.036+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.038+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.040+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:09.041+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.043+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[73] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.045+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 37.7 KiB, free 417.3 MiB)
[2025-12-10T15:03:09.050+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 417.3 MiB)
[2025-12-10T15:03:09.052+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 2be59bfabb7a:32819 (size: 17.1 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.062+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.065+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[73] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.070+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.073+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 17) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:09.077+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 204.6 KiB, free 417.1 MiB)
[2025-12-10T15:03:09.079+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 31.0 (TID 17)
[2025-12-10T15:03:09.080+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 2be59bfabb7a:32819 in memory (size: 36.0 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.083+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:09.086+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 417.5 MiB)
[2025-12-10T15:03:09.088+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.091+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 28 from count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.094+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:09.100+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:09.105+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 2be59bfabb7a:32819 in memory (size: 195.0 B, free: 434.2 MiB)
[2025-12-10T15:03:09.107+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 77 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-12-10T15:03:09.113+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.114+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.116+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:09.117+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.118+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.120+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 44.4 KiB, free 417.2 MiB)
[2025-12-10T15:03:09.123+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 417.2 MiB)
[2025-12-10T15:03:09.125+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 2be59bfabb7a:32819 (size: 19.7 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.127+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.128+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 2be59bfabb7a:32819 in memory (size: 309.0 B, free: 434.2 MiB)
[2025-12-10T15:03:09.129+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.131+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.134+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 18) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:09.139+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 32.0 (TID 18)
[2025-12-10T15:03:09.146+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:09.156+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 2be59bfabb7a:32819 in memory (size: 39.5 KiB, free: 434.3 MiB)
[2025-12-10T15:03:09.159+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:09.175+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:09.190+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:09.217+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 31.0 (TID 17). 2930 bytes result sent to driver
[2025-12-10T15:03:09.220+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 17) in 154 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.221+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.223+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.181 s
[2025-12-10T15:03:09.224+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:09.225+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-12-10T15:03:09.226+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:09.227+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:09.247+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 32.0 (TID 18). 2986 bytes result sent to driver
[2025-12-10T15:03:09.249+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 18) in 126 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.249+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.250+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.140 s
[2025-12-10T15:03:09.251+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:09.252+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:09.253+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:09.253+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:09.262+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:09.273+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:09.282+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 81 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-12-10T15:03:09.283+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.285+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.286+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-12-10T15:03:09.287+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.289+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.291+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 48.5 KiB, free 433.8 MiB)
[2025-12-10T15:03:09.293+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)
[2025-12-10T15:03:09.295+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 2be59bfabb7a:32819 (size: 21.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:09.296+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.297+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.298+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.299+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 19) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:09.301+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 34.0 (TID 19)
[2025-12-10T15:03:09.308+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:09.309+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:09.326+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 34.0 (TID 19). 5962 bytes result sent to driver
[2025-12-10T15:03:09.328+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 19) in 32 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.330+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.331+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ShuffleMapStage 34 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-12-10T15:03:09.332+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:09.333+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:09.334+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:09.335+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:09.342+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:09.391+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:09.395+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:09.399+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ResultStage 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:09.400+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2025-12-10T15:03:09.401+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.402+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[87] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:09.404+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 52.5 KiB, free 433.7 MiB)
[2025-12-10T15:03:09.407+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 433.7 MiB)
[2025-12-10T15:03:09.409+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 2be59bfabb7a:32819 (size: 23.5 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.411+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.412+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[87] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.414+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.417+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 20) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:09.418+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 37.0 (TID 20)
[2025-12-10T15:03:09.427+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Getting 1 (146.0 B) non-empty blocks including 1 (146.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:09.428+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:09.438+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 37.0 (TID 20). 7347 bytes result sent to driver
[2025-12-10T15:03:09.440+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 20) in 26 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.442+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.446+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ResultStage 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.045 s
[2025-12-10T15:03:09.448+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:09.450+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
[2025-12-10T15:03:09.452+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.051960 s
[2025-12-10T15:03:09.456+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.0 MiB, free 425.7 MiB)
[2025-12-10T15:03:09.458+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 175.0 B, free 425.7 MiB)
[2025-12-10T15:03:09.463+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 2be59bfabb7a:32819 (size: 175.0 B, free: 434.2 MiB)
[2025-12-10T15:03:09.464+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 32 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:09.465+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:09.495+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 90 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2025-12-10T15:03:09.497+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.503+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.505+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
[2025-12-10T15:03:09.507+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.508+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.510+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 72.7 KiB, free 425.6 MiB)
[2025-12-10T15:03:09.510+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 425.6 MiB)
[2025-12-10T15:03:09.512+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 2be59bfabb7a:32819 (size: 31.1 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.513+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.514+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.515+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.516+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 21) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:09.517+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 39.0 (TID 21)
[2025-12-10T15:03:09.525+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Getting 1 (120.0 B) non-empty blocks including 1 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:09.529+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:09.540+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 39.0 (TID 21). 10577 bytes result sent to driver
[2025-12-10T15:03:09.542+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 21) in 27 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.543+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.544+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0.043 s
[2025-12-10T15:03:09.545+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:09.546+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:09.548+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:09.549+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:09.573+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.574+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.575+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ResultStage 42 (count at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.576+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
[2025-12-10T15:03:09.578+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.579+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.580+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.5 KiB, free 425.6 MiB)
[2025-12-10T15:03:09.581+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.6 MiB)
[2025-12-10T15:03:09.582+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 2be59bfabb7a:32819 (size: 5.9 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.583+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.584+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.584+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.585+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 22) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:09.587+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 42.0 (TID 22)
[2025-12-10T15:03:09.592+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:09.593+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:09.596+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 42.0 (TID 22). 3995 bytes result sent to driver
[2025-12-10T15:03:09.597+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 22) in 11 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:09.597+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-12-10T15:03:09.598+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: ResultStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.021 s
[2025-12-10T15:03:09.599+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:09.602+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
[2025-12-10T15:03:09.604+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Job 22 finished: count at NativeMethodAccessorImpl.java:0, took 0.026105 s
[2025-12-10T15:03:09.605+0000] {subprocess.py:93} INFO - üìå Step 3: Writing aggregations to Gold layer...
[2025-12-10T15:03:09.716+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:09.717+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Post-Scan Filters:
[2025-12-10T15:03:09.719+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:09.720+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#148 as date))
[2025-12-10T15:03:09.727+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Pushed Filters:
[2025-12-10T15:03:09.728+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cast(date#166 as date))
[2025-12-10T15:03:09.840+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 204.6 KiB, free 425.4 MiB)
[2025-12-10T15:03:09.853+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 425.3 MiB)
[2025-12-10T15:03:09.856+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.857+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 35 from parquet at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.858+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:09.869+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 97 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 14
[2025-12-10T15:03:09.871+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 23 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.873+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.874+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:09.876+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.877+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[97] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.879+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 40.3 KiB, free 425.3 MiB)
[2025-12-10T15:03:09.880+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 425.3 MiB)
[2025-12-10T15:03:09.880+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 2be59bfabb7a:32819 (size: 18.3 KiB, free: 434.2 MiB)
[2025-12-10T15:03:09.883+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.884+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[97] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.885+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.887+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 204.8 KiB, free 425.1 MiB)
[2025-12-10T15:03:09.888+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 23) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:09.890+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 43.0 (TID 23)
[2025-12-10T15:03:09.895+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 425.0 MiB)
[2025-12-10T15:03:09.898+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 2be59bfabb7a:32819 (size: 36.0 KiB, free: 434.1 MiB)
[2025-12-10T15:03:09.899+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 37 from parquet at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.901+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:09.902+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:09.909+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 101 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 15
[2025-12-10T15:03:09.911+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 24 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.912+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.914+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:09.915+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:09.916+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[101] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:09.918+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 43.4 KiB, free 416.7 MiB)
[2025-12-10T15:03:09.928+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 204.6 KiB, free 416.5 MiB)
[2025-12-10T15:03:09.929+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:09.946+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 416.5 MiB)
[2025-12-10T15:03:09.947+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 2be59bfabb7a:32819 (size: 19.3 KiB, free: 434.1 MiB)
[2025-12-10T15:03:09.949+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:09.950+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[101] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:09.950+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-12-10T15:03:09.952+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 24) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:09.957+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Running task 0.0 in stage 44.0 (TID 24)
[2025-12-10T15:03:09.965+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 416.5 MiB)
[2025-12-10T15:03:09.967+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 2be59bfabb7a:32819 (size: 35.8 KiB, free: 434.1 MiB)
[2025-12-10T15:03:09.968+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO SparkContext: Created broadcast 39 from parquet at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:09.970+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-12-10T15:03:09.986+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Registering RDD 105 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 16
[2025-12-10T15:03:09.991+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:09.993+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Got map stage job 25 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:09.996+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:09.999+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Parents of final stage: List()
[2025-12-10T15:03:10.003+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:10.005+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[105] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:10.007+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.4 KiB, free 416.4 MiB)
[2025-12-10T15:03:10.009+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 416.4 MiB)
[2025-12-10T15:03:10.010+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO Executor: Finished task 0.0 in stage 43.0 (TID 23). 2973 bytes result sent to driver
[2025-12-10T15:03:10.012+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 2be59bfabb7a:32819 (size: 19.7 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.013+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 23) in 117 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.014+0000] {subprocess.py:93} INFO - 25/12/10 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.016+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:10.018+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[105] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:10.019+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
[2025-12-10T15:03:10.021+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 25) (2be59bfabb7a, executor driver, partition 0, PROCESS_LOCAL, 8990 bytes)
[2025-12-10T15:03:10.024+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ShuffleMapStage 43 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.133 s
[2025-12-10T15:03:10.025+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:10.026+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: running: Set(ShuffleMapStage 45, ShuffleMapStage 44)
[2025-12-10T15:03:10.028+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:10.029+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:10.030+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Running task 0.0 in stage 45.0 (TID 25)
[2025-12-10T15:03:10.032+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:10.037+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO FileScanRDD: Reading File path: s3a://datalake/bronze/emails/part-00000-c6b7678d-0464-4f61-9d60-5e489250e7f1-c000.snappy.parquet, range: 0-31319, partition values: [empty row]
[2025-12-10T15:03:10.064+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO S3AInputStream: Switching to Random IO seek policy
[2025-12-10T15:03:10.086+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 44.0 (TID 24). 2986 bytes result sent to driver
[2025-12-10T15:03:10.091+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 24) in 140 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.093+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.094+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ShuffleMapStage 44 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.181 s
[2025-12-10T15:03:10.096+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:10.097+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: running: Set(ShuffleMapStage 45)
[2025-12-10T15:03:10.098+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:10.099+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:10.126+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:10.136+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 45.0 (TID 25). 2986 bytes result sent to driver
[2025-12-10T15:03:10.140+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 25) in 133 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.142+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.143+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ShuffleMapStage 45 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.150 s
[2025-12-10T15:03:10.144+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:10.145+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:10.147+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:10.148+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:10.160+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:10.170+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Registering RDD 109 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 17
[2025-12-10T15:03:10.177+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Got map stage job 26 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:10.180+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Final stage: ShuffleMapStage 47 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:10.181+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
[2025-12-10T15:03:10.187+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:10.191+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[109] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:10.192+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 47.6 KiB, free 424.6 MiB)
[2025-12-10T15:03:10.197+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 424.6 MiB)
[2025-12-10T15:03:10.199+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 2be59bfabb7a:32819 in memory (size: 19.7 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.201+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 2be59bfabb7a:32819 (size: 21.8 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.203+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:10.207+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[109] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:10.210+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
[2025-12-10T15:03:10.212+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 26) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:10.214+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Running task 0.0 in stage 47.0 (TID 26)
[2025-12-10T15:03:10.216+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 2be59bfabb7a:32819 in memory (size: 31.1 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.220+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 2be59bfabb7a:32819 in memory (size: 21.9 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.225+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:10.227+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-12-10T15:03:10.230+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.1 MiB)
[2025-12-10T15:03:10.239+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 2be59bfabb7a:32819 in memory (size: 18.3 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.243+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:10.256+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 2be59bfabb7a:32819 in memory (size: 19.7 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.272+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 2be59bfabb7a:32819 in memory (size: 23.5 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.286+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 2be59bfabb7a:32819 in memory (size: 35.8 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.295+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 47.0 (TID 26). 6005 bytes result sent to driver
[2025-12-10T15:03:10.298+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 2be59bfabb7a:32819 in memory (size: 17.1 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.299+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 26) in 93 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.301+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.302+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:10.304+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ShuffleMapStage 47 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.124 s
[2025-12-10T15:03:10.306+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:10.308+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:10.309+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:10.309+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:10.310+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 2be59bfabb7a:32819 in memory (size: 19.3 KiB, free: 434.3 MiB)
[2025-12-10T15:03:10.318+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 2be59bfabb7a:32819 in memory (size: 175.0 B, free: 434.3 MiB)
[2025-12-10T15:03:10.320+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Registering RDD 113 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-12-10T15:03:10.323+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Got map stage job 27 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:10.326+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:10.330+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
[2025-12-10T15:03:10.332+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:10.335+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[113] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:10.340+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 48.9 KiB, free 433.6 MiB)
[2025-12-10T15:03:10.341+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.5 MiB)
[2025-12-10T15:03:10.344+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 2be59bfabb7a:32819 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-12-10T15:03:10.346+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 2be59bfabb7a:32819 (size: 22.0 KiB, free: 434.3 MiB)
[2025-12-10T15:03:10.348+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:10.349+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[113] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:10.350+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-12-10T15:03:10.351+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 27) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8331 bytes)
[2025-12-10T15:03:10.352+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Running task 0.0 in stage 49.0 (TID 27)
[2025-12-10T15:03:10.371+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:10.373+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:10.377+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-12-10T15:03:10.380+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 2be59bfabb7a:32819 in memory (size: 21.8 KiB, free: 434.3 MiB)
[2025-12-10T15:03:10.402+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 49.0 (TID 27). 6048 bytes result sent to driver
[2025-12-10T15:03:10.403+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 27) in 56 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.406+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.408+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ShuffleMapStage 49 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.078 s
[2025-12-10T15:03:10.409+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: looking for newly runnable stages
[2025-12-10T15:03:10.411+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: running: Set()
[2025-12-10T15:03:10.412+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: waiting: Set()
[2025-12-10T15:03:10.413+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: failed: Set()
[2025-12-10T15:03:10.426+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:10.442+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:10.445+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:10.479+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Final stage: ResultStage 52 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:10.481+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
[2025-12-10T15:03:10.483+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:10.484+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[121] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:10.485+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 56.7 KiB, free 433.6 MiB)
[2025-12-10T15:03:10.487+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 433.5 MiB)
[2025-12-10T15:03:10.489+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 2be59bfabb7a:32819 (size: 25.1 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.491+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:10.492+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[121] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:10.493+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-12-10T15:03:10.494+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 28) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:10.496+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Running task 0.0 in stage 52.0 (TID 28)
[2025-12-10T15:03:10.497+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Getting 1 (325.0 B) non-empty blocks including 1 (325.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:10.498+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-12-10T15:03:10.528+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:10.530+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-12-10T15:03:10.532+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-12-10T15:03:10.534+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-12-10T15:03:10.535+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:10.541+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[127] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-12-10T15:03:10.542+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 53.2 KiB, free 433.5 MiB)
[2025-12-10T15:03:10.543+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 433.5 MiB)
[2025-12-10T15:03:10.545+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 2be59bfabb7a:32819 (size: 23.6 KiB, free: 434.2 MiB)
[2025-12-10T15:03:10.546+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:10.548+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[127] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:10.549+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-12-10T15:03:10.550+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 29) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:10.551+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Running task 0.0 in stage 55.0 (TID 29)
[2025-12-10T15:03:10.555+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 52.0 (TID 28). 7887 bytes result sent to driver
[2025-12-10T15:03:10.558+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 28) in 80 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.560+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.561+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Getting 1 (160.0 B) non-empty blocks including 1 (160.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:10.562+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-12-10T15:03:10.564+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ResultStage 52 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.109 s
[2025-12-10T15:03:10.565+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:10.568+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
[2025-12-10T15:03:10.571+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.116810 s
[2025-12-10T15:03:10.573+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 8.0 MiB, free 425.4 MiB)
[2025-12-10T15:03:10.575+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 309.0 B, free 417.4 MiB)
[2025-12-10T15:03:10.576+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 2be59bfabb7a:32819 (size: 309.0 B, free: 434.2 MiB)
[2025-12-10T15:03:10.577+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:10.584+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO Executor: Finished task 0.0 in stage 55.0 (TID 29). 7323 bytes result sent to driver
[2025-12-10T15:03:10.585+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 29) in 41 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:10.586+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-12-10T15:03:10.587+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.053 s
[2025-12-10T15:03:10.589+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:10.590+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-12-10T15:03:10.591+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.059325 s
[2025-12-10T15:03:10.593+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 8.0 MiB, free 417.5 MiB)
[2025-12-10T15:03:10.594+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 195.0 B, free 417.5 MiB)
[2025-12-10T15:03:10.595+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 2be59bfabb7a:32819 (size: 195.0 B, free: 434.2 MiB)
[2025-12-10T15:03:10.595+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-12-10T15:03:10.599+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-12-10T15:03:10.657+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-12-10T15:03:10.676+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-12-10T15:03:10.677+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-12-10T15:03:10.677+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-12-10T15:03:10.678+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-12-10T15:03:10.679+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-12-10T15:03:10.679+0000] {subprocess.py:93} INFO - 25/12/10 15:03:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-12-10T15:03:11.154+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-12-10T15:03:11.196+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO CodeGenerator: Code generated in 20.250389 ms
[2025-12-10T15:03:11.221+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-12-10T15:03:11.228+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Got job 30 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-12-10T15:03:11.230+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at NativeMethodAccessorImpl.java:0)
[2025-12-10T15:03:11.232+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-12-10T15:03:11.234+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Missing parents: List()
[2025-12-10T15:03:11.236+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[130] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-12-10T15:03:11.266+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 300.5 KiB, free 417.2 MiB)
[2025-12-10T15:03:11.270+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 110.7 KiB, free 417.1 MiB)
[2025-12-10T15:03:11.272+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 2be59bfabb7a:32819 (size: 110.7 KiB, free: 434.1 MiB)
[2025-12-10T15:03:11.274+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1580
[2025-12-10T15:03:11.276+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[130] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-12-10T15:03:11.277+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-12-10T15:03:11.278+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 30) (2be59bfabb7a, executor driver, partition 0, NODE_LOCAL, 8342 bytes)
[2025-12-10T15:03:11.279+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO Executor: Running task 0.0 in stage 57.0 (TID 30)
[2025-12-10T15:03:11.319+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO ShuffleBlockFetcherIterator: Getting 1 (132.0 B) non-empty blocks including 1 (132.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-12-10T15:03:11.320+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-12-10T15:03:11.341+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO CodeGenerator: Code generated in 20.84013 ms
[2025-12-10T15:03:11.344+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-12-10T15:03:11.346+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-12-10T15:03:11.347+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-12-10T15:03:11.348+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-12-10T15:03:11.348+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-12-10T15:03:11.349+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-12-10T15:03:11.355+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO CodecConfig: Compression: SNAPPY
[2025-12-10T15:03:11.359+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO CodecConfig: Compression: SNAPPY
[2025-12-10T15:03:11.384+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-12-10T15:03:11.402+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-12-10T15:03:11.404+0000] {subprocess.py:93} INFO - {
[2025-12-10T15:03:11.405+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2025-12-10T15:03:11.409+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2025-12-10T15:03:11.409+0000] {subprocess.py:93} INFO -     "name" : "date",
[2025-12-10T15:03:11.410+0000] {subprocess.py:93} INFO -     "type" : "date",
[2025-12-10T15:03:11.411+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2025-12-10T15:03:11.411+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2025-12-10T15:03:11.412+0000] {subprocess.py:93} INFO -   }, {
[2025-12-10T15:03:11.412+0000] {subprocess.py:93} INFO -     "name" : "total_emails",
[2025-12-10T15:03:11.413+0000] {subprocess.py:93} INFO -     "type" : "long",
[2025-12-10T15:03:11.413+0000] {subprocess.py:93} INFO -     "nullable" : false,
[2025-12-10T15:03:11.414+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2025-12-10T15:03:11.414+0000] {subprocess.py:93} INFO -   }, {
[2025-12-10T15:03:11.415+0000] {subprocess.py:93} INFO -     "name" : "domain_counts",
[2025-12-10T15:03:11.415+0000] {subprocess.py:93} INFO -     "type" : "string",
[2025-12-10T15:03:11.416+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2025-12-10T15:03:11.416+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2025-12-10T15:03:11.417+0000] {subprocess.py:93} INFO -   }, {
[2025-12-10T15:03:11.418+0000] {subprocess.py:93} INFO -     "name" : "busiest_hour",
[2025-12-10T15:03:11.418+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2025-12-10T15:03:11.419+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2025-12-10T15:03:11.420+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2025-12-10T15:03:11.420+0000] {subprocess.py:93} INFO -   }, {
[2025-12-10T15:03:11.421+0000] {subprocess.py:93} INFO -     "name" : "busiest_hour_count",
[2025-12-10T15:03:11.422+0000] {subprocess.py:93} INFO -     "type" : "long",
[2025-12-10T15:03:11.423+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2025-12-10T15:03:11.426+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2025-12-10T15:03:11.427+0000] {subprocess.py:93} INFO -   } ]
[2025-12-10T15:03:11.428+0000] {subprocess.py:93} INFO - }
[2025-12-10T15:03:11.429+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-12-10T15:03:11.430+0000] {subprocess.py:93} INFO - message spark_schema {
[2025-12-10T15:03:11.432+0000] {subprocess.py:93} INFO -   optional int32 date (DATE);
[2025-12-10T15:03:11.433+0000] {subprocess.py:93} INFO -   required int64 total_emails;
[2025-12-10T15:03:11.433+0000] {subprocess.py:93} INFO -   optional binary domain_counts (STRING);
[2025-12-10T15:03:11.434+0000] {subprocess.py:93} INFO -   optional int32 busiest_hour;
[2025-12-10T15:03:11.434+0000] {subprocess.py:93} INFO -   optional int64 busiest_hour_count;
[2025-12-10T15:03:11.435+0000] {subprocess.py:93} INFO - }
[2025-12-10T15:03:11.435+0000] {subprocess.py:93} INFO - 
[2025-12-10T15:03:11.436+0000] {subprocess.py:93} INFO - 
[2025-12-10T15:03:11.519+0000] {subprocess.py:93} INFO - 25/12/10 15:03:11 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-12-10T15:03:12.103+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO FileOutputCommitter: Saved output of task 'attempt_20251210150311938752217508216892_0057_m_000000_30' to s3a://datalake/gold/daily_summary/_temporary/0/task_20251210150311938752217508216892_0057_m_000000
[2025-12-10T15:03:12.105+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO SparkHadoopMapRedUtil: attempt_20251210150311938752217508216892_0057_m_000000_30: Committed. Elapsed time: 183 ms.
[2025-12-10T15:03:12.118+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO Executor: Finished task 0.0 in stage 57.0 (TID 30). 16271 bytes result sent to driver
[2025-12-10T15:03:12.120+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 30) in 844 ms on 2be59bfabb7a (executor driver) (1/1)
[2025-12-10T15:03:12.121+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-12-10T15:03:12.123+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO DAGScheduler: ResultStage 57 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.889 s
[2025-12-10T15:03:12.125+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-12-10T15:03:12.126+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-12-10T15:03:12.126+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO DAGScheduler: Job 30 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.902597 s
[2025-12-10T15:03:12.127+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO FileFormatWriter: Start to commit write Job 65c5ce93-7396-45e3-863e-916087cb0e15.
[2025-12-10T15:03:12.419+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO FileFormatWriter: Write Job 65c5ce93-7396-45e3-863e-916087cb0e15 committed. Elapsed time: 291 ms.
[2025-12-10T15:03:12.425+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO FileFormatWriter: Finished processing stats for write job 65c5ce93-7396-45e3-863e-916087cb0e15.
[2025-12-10T15:03:12.431+0000] {subprocess.py:93} INFO - ‚úÖ Gold layer written successfully!
[2025-12-10T15:03:12.433+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-12-10T15:03:12.463+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO SparkUI: Stopped Spark web UI at http://2be59bfabb7a:4040
[2025-12-10T15:03:12.482+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-12-10T15:03:12.516+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO MemoryStore: MemoryStore cleared
[2025-12-10T15:03:12.518+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO BlockManager: BlockManager stopped
[2025-12-10T15:03:12.522+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-12-10T15:03:12.531+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-12-10T15:03:12.565+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO SparkContext: Successfully stopped SparkContext
[2025-12-10T15:03:12.645+0000] {subprocess.py:93} INFO - ============================================================
[2025-12-10T15:03:12.646+0000] {subprocess.py:93} INFO - ‚úÖ DAILY AGGREGATION JOB COMPLETED SUCCESSFULLY
[2025-12-10T15:03:12.940+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO ShutdownHookManager: Shutdown hook called
[2025-12-10T15:03:12.941+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-155d3237-197a-4061-a417-80e4ecce1b69
[2025-12-10T15:03:12.950+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e
[2025-12-10T15:03:12.957+0000] {subprocess.py:93} INFO - 25/12/10 15:03:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-9959ca2a-371b-4fe9-869e-461221dfde9e/pyspark-389288b3-9799-4d89-8f41-8d07fcec825b
[2025-12-10T15:03:13.065+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-10T15:03:13.172+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=email_intelligence_pipeline, task_id=daily_insights_aggregation, execution_date=20251210T140137, start_date=20251210T150245, end_date=20251210T150313
[2025-12-10T15:03:13.213+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-12-10T15:03:13.264+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
