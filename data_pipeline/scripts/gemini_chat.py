#!/usr/bin/env python3
"""
Chat intelligent Emails avec :
- Routeur LLM-based (robuste)
- Gestion today / yesterday / last week (TIMESTAMP SAFE)
- RAG hybride SQL + pgvector
"""

from typing import List, Dict, Tuple
import psycopg2
import datetime
import json
from openai import OpenAI
import re
from collections import Counter, defaultdict
import os

# ---------------- CONFIGURATION ----------------

PG_HOST = "localhost"
PG_PORT = "5432"
PG_DB = "projetformationdb"
PG_USER = "postgres"
PG_PASSWORD = "secret"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") # üîê mets ta vraie cl√© OpenAI ici
CHAT_MODEL = "gpt-4"
EMBED_MODEL = "text-embedding-3-small"

USER_EMAIL = "alaehaddad205@gmail.com"

client = OpenAI(api_key=OPENAI_API_KEY)

# ---------------- CONVERSATION CONTEXT ----------------

class ConversationContext:
    """M√©moire simple des derniers emails retourn√©s et email s√©lectionn√©."""

    def __init__(self):
        self.last_emails: List[Dict] = []
        self.selected_email: Dict = None

    def set_emails(self, emails: List[Dict]):
        self.last_emails = emails or []
        self.selected_email = None

    def select(self, idx: int) -> Dict:
        if 1 <= idx <= len(self.last_emails):
            self.selected_email = self.last_emails[idx - 1]
            return self.selected_email
        return None

    def get_selected(self) -> Dict:
        return self.selected_email

# ---------------- DATABASE ----------------

def get_db_connection():
    return psycopg2.connect(
        host=PG_HOST,
        port=PG_PORT,
        dbname=PG_DB,
        user=PG_USER,
        password=PG_PASSWORD
    )

# ---------------- EMBEDDING ----------------

def embed_question(text: str) -> list:
    res = client.embeddings.create(
        model=EMBED_MODEL,
        input=text
    )
    return res.data[0].embedding

# ---------------- SENTIMENT ANALYSIS ----------------

def analyze_sentiment(text: str) -> Dict:
    """
    Analyse le sentiment d'un email en utilisant OpenAI.
    Retourne: {"sentiment": "positive|negative|neutral", "score": float, "emoji": str}
    """
    try:
        prompt = f"""Analyse le sentiment de cet email et retourne UNIQUEMENT un JSON valide:
{{
  "sentiment": "positive" ou "negative" ou "neutral",
  "score": score de 0 √† 1,
  "emoji": emoji appropri√© (üòä pour positif, üòü pour n√©gatif, üòê pour neutre)
}}

Email: {text[:500]}"""
        
        res = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return json.loads(res.choices[0].message.content)
    except Exception as e:
        print(f"‚ö†Ô∏è Sentiment analysis error: {e}")
        return {"sentiment": "neutral", "score": 0.5, "emoji": "üòê"}

def batch_analyze_sentiments(emails: List[Dict]) -> List[Dict]:
    """
    Analyse les sentiments de plusieurs emails et les ajoute aux objets email.
    """
    for email in emails:
        sentiment_data = analyze_sentiment(email.get('body', '') or email.get('subject', ''))
        email['sentiment'] = sentiment_data['sentiment']
        email['sentiment_score'] = sentiment_data['score']
        email['sentiment_emoji'] = sentiment_data['emoji']
    return emails

# ---------------- ROUTEUR LLM ----------------

def route_intent(question: str) -> Dict:
    system_prompt = """
Tu es un routeur intelligent qui analyse les questions sur les emails.
Retourne UNIQUEMENT un JSON valide.

Format strict :
{
  "intent": "TEMPORAL | SEMANTIC | HYBRID | SPECIFIC_DATE | IMPORTANT",
  "period": "today | yesterday | last_week | null",
  "specific_date": "YYYY-MM-DD | null"
}

R√®gles :
- "Good morning" / "today" / "yesterday" => TEMPORAL avec period appropri√©
- "emails du 17 d√©cembre" / "le 19 d√©cembre" => SPECIFIC_DATE avec specific_date: "2025-12-17"
- "emails importants" / "important emails" / "quels sont mes emails importants" => IMPORTANT
- Question vague sur contenu => SEMANTIC
- Date + sujet => HYBRID

Exemples :
- "emails re√ßus le 17 d√©cembre" => {"intent": "SPECIFIC_DATE", "period": null, "specific_date": "2025-12-17"}
- "today" => {"intent": "TEMPORAL", "period": "today", "specific_date": null}
- "emails importants" => {"intent": "IMPORTANT", "period": null, "specific_date": null}
- "emails about invoices last week" => {"intent": "HYBRID", "period": "last_week", "specific_date": null}

IMPORTANT : Pour les dates en fran√ßais, utilise l'ann√©e 2025 par d√©faut.
"""

    try:
        res = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            temperature=0  # ‚úÖ Pour plus de coh√©rence
        )

        data = json.loads(res.choices[0].message.content)
        if "intent" not in data:
            raise ValueError("Missing intent field")

        return data

    except Exception as e:
        print(f"‚ö†Ô∏è Router error: {e}")
        # Fallback s√ªr
        return {"intent": "SEMANTIC", "period": None, "specific_date": None}

# ---------------- DATE RANGE (CORRIG√â) ----------------

def fetch_emails_by_specific_date(user_id: str, date_str: str) -> List[Dict]:
    """
    R√©cup√®re les emails d'une date sp√©cifique au format YYYY-MM-DD
    Exemple: "2025-12-17"
    """
    try:
        # Parser la date
        target_date = datetime.datetime.strptime(date_str, "%Y-%m-%d").date()
        
        # Cr√©er le range pour toute la journ√©e
        start = datetime.datetime.combine(target_date, datetime.time.min)
        end = datetime.datetime.combine(target_date, datetime.time.max)
        
        conn = get_db_connection()
        cur = conn.cursor()

        query = """
            SELECT email_id, subject, body, sender, receiver, date,
                   is_important, sender_domain
            FROM email_embeddings
            WHERE receiver = %s
              AND date >= %s
              AND date <= %s
            ORDER BY date DESC
        """

        cur.execute(query, (user_id, start, end))
        rows = cur.fetchall()

        cur.close()
        conn.close()

        return [
            {
                "id": r[0],
                "subject": r[1],
                "body": r[2],
                "sender": r[3],
                "receiver": r[4],
                "date": r[5],
                "is_important": r[6],
                "sender_domain": r[7],
                "similarity": 1.0
            }
            for r in rows
        ]
    
    except Exception as e:
        print(f"‚ùå Error fetching emails for date {date_str}: {e}")
        return []

# ---------------- DATE RANGE (CORRIG√â) ----------------

def get_date_range(period: str):
    now = datetime.datetime.now()

    if period == "today":
        start = datetime.datetime.combine(now.date(), datetime.time.min)
        end = datetime.datetime.combine(now.date(), datetime.time.max)

    elif period == "yesterday":
        d = now.date() - datetime.timedelta(days=1)
        start = datetime.datetime.combine(d, datetime.time.min)
        end = datetime.datetime.combine(d, datetime.time.max)

    elif period == "last_week":
        start = now - datetime.timedelta(days=7)
        end = now

    else:
        return None, None

    return start, end

# ---------------- SQL TEMPORAL ----------------

def fetch_emails_by_date(user_id: str, period: str) -> List[Dict]:
    start, end = get_date_range(period)
    if not start:
        return []

    conn = get_db_connection()
    cur = conn.cursor()

    query = """
        SELECT email_id, subject, body, sender, receiver, date,
               is_important, sender_domain
        FROM email_embeddings
        WHERE receiver = %s
          AND date >= %s
          AND date <= %s
        ORDER BY date DESC
    """

    cur.execute(query, (user_id, start, end))
    rows = cur.fetchall()

    cur.close()
    conn.close()

    return [
        {
            "id": r[0],
            "subject": r[1],
            "body": r[2],
            "sender": r[3],
            "receiver": r[4],
            "date": r[5],
            "is_important": r[6],
            "sender_domain": r[7],
            "similarity": 1.0
        }
        for r in rows
    ]

# ---------------- PGVECTOR ----------------

def search_similar_emails(question: str, user_id: str, top_k: int = 5) -> List[Dict]:
    embedding = embed_question(question)

    conn = get_db_connection()
    cur = conn.cursor()

    query = """
        SELECT email_id, subject, body, sender, receiver, date,
               is_important, sender_domain,
               1 - (body_embedding <-> %s::vector) AS similarity
        FROM email_embeddings
        WHERE receiver = %s
        ORDER BY body_embedding <-> %s::vector
        LIMIT %s
    """

    cur.execute(query, (embedding, user_id, embedding, top_k))
    rows = cur.fetchall()

    cur.close()
    conn.close()

    return [
        {
            "id": r[0],
            "subject": r[1],
            "body": r[2],
            "sender": r[3],
            "receiver": r[4],
            "date": r[5],
            "is_important": r[6],
            "sender_domain": r[7],
            "similarity": round(r[8], 3)
        }
        for r in rows
    ]

# ---------------- EMAIL STATISTICS ----------------

def get_email_statistics(user_id: str, period: str = "today") -> Dict:
    """
    G√©n√®re des statistiques compl√®tes sur les emails:
    - Nombre total d'emails
    - Emails urgents/importants
    - Top senders
    - Analyse de sentiment globale
    - Actions requises
    """
    start, end = get_date_range(period)
    if not start:
        return {}
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # Requ√™te pour r√©cup√©rer tous les emails de la p√©riode
    query = """
        SELECT email_id, subject, body, sender, receiver, date,
               is_important, sender_domain
        FROM email_embeddings
        WHERE receiver = %s
          AND date >= %s
          AND date <= %s
        ORDER BY date DESC
    """
    
    cur.execute(query, (user_id, start, end))
    rows = cur.fetchall()
    cur.close()
    conn.close()
    
    # Conversion en liste de dictionnaires
    emails = [
        {
            "id": r[0],
            "subject": r[1],
            "body": r[2],
            "sender": r[3],
            "receiver": r[4],
            "date": r[5],
            "is_important": r[6],
            "sender_domain": r[7]
        }
        for r in rows
    ]
    
    # Calcul des statistiques
    total_emails = len(emails)
    urgent_emails = sum(1 for e in emails if e['is_important'])
    
    # Top senders (comptage des emails par exp√©diteur)
    sender_counter = Counter(e['sender'] for e in emails)
    top_senders = sender_counter.most_common(3)
    
    # Analyse de sentiment sur un √©chantillon
    sample_size = min(20, len(emails))  # Analyser max 20 emails pour performance
    sampled_emails = emails[:sample_size]
    sentiments = {'positive': 0, 'negative': 0, 'neutral': 0}
    
    for email in sampled_emails:
        sentiment = analyze_sentiment(email['body'] or email['subject'])
        sentiments[sentiment['sentiment']] += 1
    
    # D√©tection des actions requises (emails importants r√©cents)
    action_required = [
        {
            'sender': e['sender'],
            'subject': e['subject'],
            'reason': 'Marked as important',
            'date': e['date']
        }
        for e in emails[:5] if e['is_important']
    ]
    
    return {
        'total_emails': total_emails,
        'urgent_emails': urgent_emails,
        'top_senders': top_senders,
        'sentiments': sentiments,
        'action_required': action_required,
        'period': period
    }

# ---------------- IMPORTANT EMAILS ----------------

def fetch_important_emails(user_id: str) -> List[Dict]:
    """R√©cup√®re uniquement les emails marqu√©s comme importants (is_important=true)."""
    conn = get_db_connection()
    cur = conn.cursor()

    query = """
        SELECT email_id, subject, body, sender, receiver, date,
               is_important, sender_domain
        FROM email_embeddings
        WHERE receiver = %s
          AND is_important = true
        ORDER BY date DESC
    """

    cur.execute(query, (user_id,))
    rows = cur.fetchall()

    cur.close()
    conn.close()

    return [
        {
            "id": r[0],
            "subject": r[1],
            "body": r[2],
            "sender": r[3],
            "receiver": r[4],
            "date": r[5],
            "is_important": r[6],
            "sender_domain": r[7],
            "similarity": 1.0
        }
        for r in rows
    ]

# ---------------- MORNING BRIEFING ----------------

def generate_morning_briefing(user_id: str) -> str:
    """
    G√©n√®re un briefing matinal complet avec:
    - Statistiques des emails
    - Analyse de sentiment
    - Actions requises
    - Suggestions
    """
    stats = get_email_statistics(user_id, "today")
    
    if not stats or stats['total_emails'] == 0:
        return "‚òÄÔ∏è Good morning! No new emails today yet."
    
    # Construction du briefing format√©
    briefing = f"""‚òÄÔ∏è Good morning! Here's your briefing for {datetime.datetime.now().strftime('%B %d, %Y')}:

üìß EMAIL INSIGHTS (last 24 hours):
‚Ä¢ {stats['total_emails']} new emails received
‚Ä¢ {stats['urgent_emails']} require urgent response (flagged as important)
"""
    
    # Top senders
    if stats['top_senders']:
        top_senders_str = ", ".join([f"{sender} ({count})" for sender, count in stats['top_senders']])
        briefing += f"‚Ä¢ Top senders: {top_senders_str}\n"
    
    # Sentiment analysis
    sentiments = stats['sentiments']
    briefing += f"‚Ä¢ Sentiment analysis: {sentiments['positive']} positive, {sentiments['negative']} negative, {sentiments['neutral']} neutral\n"
    
    # Actions requises
    if stats['action_required']:
        briefing += "\n‚ö° ACTION REQUIRED:\n"
        for action in stats['action_required'][:3]:  # Top 3 actions
            briefing += f"‚Ä¢ {action['sender']}: {action['subject'][:60]}...\n"
    
    # Suggestions intelligentes
    briefing += "\nüí° SUGGESTIONS:\n"
    if stats['urgent_emails'] > 5:
        briefing += "‚Ä¢ You have many urgent emails. Consider prioritizing responses.\n"
    if sentiments['negative'] > 2:
        briefing += f"‚Ä¢ {sentiments['negative']} emails show negative sentiment. Review for potential issues.\n"
    if stats['total_emails'] > 30:
        briefing += "‚Ä¢ High email volume today. Consider batch processing similar emails.\n"
    
    return briefing

# ---------------- SMART SUGGESTIONS ----------------

def generate_smart_suggestions(emails: List[Dict]) -> List[str]:
    """
    G√©n√®re des suggestions intelligentes bas√©es sur l'analyse des emails.
    """
    suggestions = []
    
    if not emails:
        return suggestions
    
    # D√©tecter les threads multiples du m√™me exp√©diteur
    sender_counter = Counter(e['sender'] for e in emails)
    for sender, count in sender_counter.items():
        if count >= 3:
            suggestions.append(f"‚ö†Ô∏è {sender} sent {count} emails. This might be escalating.")
    
    # D√©tecter les emails urgents
    urgent_count = sum(1 for e in emails if e.get('is_important'))
    if urgent_count > 0:
        suggestions.append(f"üö® {urgent_count} urgent email(s) require immediate attention.")
    
    # D√©tecter les mots-cl√©s critiques dans les sujets
    critical_keywords = ['urgent', 'asap', 'emergency', 'critical', 'deadline', 'issue', 'problem']
    for email in emails[:5]:  # Check top 5 emails
        subject_lower = (email.get('subject') or '').lower()
        for keyword in critical_keywords:
            if keyword in subject_lower:
                suggestions.append(f"‚ö° Email contains '{keyword}': {email['subject'][:50]}...")
                break
    
    return suggestions[:5]  # Limiter √† 5 suggestions max

# ---------------- FOLLOW-UP QUESTIONS ----------------

def generate_followup_questions(emails: List[Dict], current_query: str) -> List[str]:
    """
    G√©n√®re des questions de follow-up pertinentes bas√©es sur le contexte.
    """
    questions = []
    
    if not emails:
        return [
            "Would you like to check emails from a different time period?",
            "Should I search for emails from a specific sender?"
        ]
    
    # Questions bas√©es sur le contexte
    if len(emails) > 1:
        questions.append(f"Would you like me to summarize all {len(emails)} emails?")
        questions.append("Should I draft a response to any specific email?")
    
    # Si emails importants d√©tect√©s
    urgent_count = sum(1 for e in emails if e.get('is_important'))
    if urgent_count > 0:
        questions.append(f"Would you like to prioritize the {urgent_count} urgent email(s)?")
    
    # Si m√™me exp√©diteur multiple fois
    sender_counter = Counter(e['sender'] for e in emails)
    for sender, count in sender_counter.most_common(1):
        if count > 1:
            questions.append(f"Should I consolidate all {count} emails from {sender}?")
    
    # Questions d'action
    questions.append("Would you like me to schedule a follow-up for any of these?")
    questions.append("Should I create a summary report for these emails?")
    
    return questions[:3]  # Limiter √† 3 questions

# ---------------- CONTEXT ----------------

def format_context(emails: List[Dict], include_sentiment: bool = True) -> str:
    """
    Formate les emails en contexte lisible avec analyse de sentiment optionnelle.
    """
    if not emails:
        return "Aucun email trouv√©."

    text = f"üìß {len(emails)} Email(s) pertinent(s) :\n\n"
    
    for i, e in enumerate(emails, 1):
        # Emoji pour importance
        importance_emoji = "üö®" if e.get('is_important') else "üì®"
        
        # Formatage avec sentiment si demand√©
        text += f"{importance_emoji} --- Email {i} ---\n"
        text += f"De: {e['sender']}\n"
        text += f"Sujet: {e['subject']}\n"
        text += f"Date: {e['date']}\n"
        
        # Ajouter sentiment si disponible
        if include_sentiment and 'sentiment' in e:
            text += f"Sentiment: {e['sentiment_emoji']} {e['sentiment'].capitalize()}\n"
        
        text += f"Contenu: {e['body'][:600]}...\n\n"
    
    # Ajouter suggestions intelligentes
    suggestions = generate_smart_suggestions(emails)
    if suggestions:
        text += "\nüí° SUGGESTIONS:\n"
        for suggestion in suggestions:
            text += f"‚Ä¢ {suggestion}\n"
    
    return text

# ---------------- DRAFT RESPONSES ----------------

def draft_email_response(email: Dict, instruction: str = "") -> str:
    """
    G√©n√®re un draft de r√©ponse pour un email sp√©cifique.
    """
    prompt = f"""G√©n√®re une r√©ponse professionnelle et concise (2-4 paragraphes) √† cet email.

Email original:
De: {email['sender']}
Sujet: {email['subject']}
Contenu: {email['body'][:800]}

Instructions suppl√©mentaires: {instruction or 'R√©ponse professionnelle standard'}

Format de la r√©ponse:
Subject: Re: [sujet]

[Salutation professionnelle]

[Corps du message]

[Formule de politesse]
[Signature]
"""
    
    try:
        res = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        draft = res.choices[0].message.content
        
        # Ajouter des actions sugg√©r√©es
        actions = f"""\n---\nüìé ACTIONS DISPONIBLES:
1. 'send' - Envoyer ce draft
2. 'edit' - Modifier le draft
3. 'schedule' - Programmer l'envoi
4. 'add reminder' - Ajouter un rappel de suivi
"""
        
        return draft + actions
        
    except Exception as e:
        return f"‚ùå Erreur lors de la g√©n√©ration du draft: {e}"

# ---------------- FINAL LLM ----------------
def ask_openai(question: str, context: str, emails: List[Dict] = None) -> str:
    """Use OpenAI chat completions with EXPLICIT instructions and follow-up questions."""
    
    # ‚úÖ Prompt plus directif avec instructions pour suggestions
    system_prompt = """Tu es Mini-Mindy, un assistant email intelligent et proactif.

R√àGLES ABSOLUES :
1. Tu DOIS analyser les emails fournis dans le contexte
2. Si le contexte contient "Aucun email trouv√©", dis-le clairement
3. Sinon, r√©ponds UNIQUEMENT en te basant sur les emails fournis
4. JAMAIS de r√©ponse g√©n√©rique du type "I don't have access to..."
5. Format : utilise des emojis (üìß ‚úÖ ‚ö° üí° üéØ) et structure claire
6. Fournis des analyses approfondies : sentiment, urgence, actions sugg√©r√©es
7. Termine TOUJOURS par des questions de follow-up pertinentes

CONTEXTE DES EMAILS :
{context}
"""
    
    try:
        res = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt.format(context=context)},
                {"role": "user", "content": question}
            ],
            max_completion_tokens=1000
        )
        
        content = res.choices[0].message.content
        
        if content:
            response = content.strip()
            
            # Ajouter des follow-up questions si des emails sont fournis
            if emails:
                followup = generate_followup_questions(emails, question)
                if followup:
                    response += "\n\nü§î FOLLOW-UP QUESTIONS:\n"
                    for i, q in enumerate(followup, 1):
                        response += f"{i}. {q}\n"
            
            return response
        else:
            return "‚ùå Pas de r√©ponse g√©n√©r√©e."
            
    except Exception as e:
        return f"‚ùå Erreur OpenAI: {e}"
# ---------------- CHAT LOOP ----------------

def chat_loop(user_id: str):
    print("\nüí¨ Mini-Mindy - Chat Emails Intelligent (exit pour quitter)\n")
    print("üí° Commandes sp√©ciales:")
    print("  ‚Ä¢ 'good morning' ou 'briefing' - Briefing matinal complet")
    print("  ‚Ä¢ 'draft reply to email N' - G√©n√©rer un draft de r√©ponse")
    print("  ‚Ä¢ 'summarize email N' - R√©sumer un email sp√©cifique")
    print("  ‚Ä¢ 'important emails' - Voir les emails importants\n")
    
    conv = ConversationContext()

    while True:
        question = input("Vous : ").strip()
        if question.lower() in ["exit", "quit", "q"]:
            break

        # ==================== MORNING BRIEFING ====================
        # D√©tecte: "good morning", "briefing", "what do I need to know"
        if re.search(r"good morning|briefing|what.*need.*know|morning summary", question, re.I):
            print("\n" + generate_morning_briefing(user_id))
            continue

        # D√©tecter s√©lection/action locale (ex: "email 3", "draft reply to email 3")
        sel = re.search(r"email\s*(?:num(?:√©ro|ber)?\s*)?(\d+)", question, re.I)
        wants_reply = bool(re.search(r"draft|reply|respond|r[e√©]pond", question, re.I))
        wants_summarize = bool(re.search(r"resume|summariz|r[e√©]sume", question, re.I))

        # Si la requ√™te contient une s√©lection explicite
        if sel:
            idx = int(sel.group(1))
            selected = conv.select(idx)
            if not selected:
                print("‚ùå Aucun email en m√©moire pour ce num√©ro. Faites d'abord une recherche (ex: 'show my important emails').")
                continue

            # ==================== DRAFT REPLY ====================
            # Si demande de r√©ponse dans la m√™me phrase
            if wants_reply:
                # Extraire les instructions suppl√©mentaires
                instruction_match = re.search(r"(?:draft|reply).*?(?:saying|about|for|at)\s+(.+)", question, re.I)
                instruction = instruction_match.group(1) if instruction_match else ""
                
                draft = draft_email_response(selected, instruction)
                print(f"\nü§ñ Mini-Mindy (Draft g√©n√©r√©):\n{draft}\n")
                continue

            # ==================== SUMMARIZE ====================
            # Si demande de r√©sum√© avec analyse de sentiment
            if wants_summarize:
                # Ajouter l'analyse de sentiment
                sentiment = analyze_sentiment(selected.get('body') or '')
                
                prompt = f"""R√©sume cet email en incluant:
1. R√©sum√© principal (2-3 phrases)
2. Points cl√©s d'action
3. Urgence/Priorit√©

Email: {selected.get('body') or ''}"""
                
                context = format_context([selected], include_sentiment=True)
                answer = ask_openai(prompt, context, [selected])
                
                print(f"\nü§ñ Mini-Mindy (R√©sum√© avec analyse):\n")
                print(f"Sentiment: {sentiment['emoji']} {sentiment['sentiment'].capitalize()}\n")
                print(f"{answer}\n")
                continue

            # ==================== DISPLAY EMAIL ====================
            # Sinon afficher le mail s√©lectionn√© avec sentiment
            selected_with_sentiment = batch_analyze_sentiments([selected])[0]
            print(format_context([selected_with_sentiment], include_sentiment=True))
            continue

        # Sinon utiliser le routeur LLM
        route = route_intent(question)
        intent = route.get("intent")
        period = route.get("period")
        specific_date = route.get("specific_date")

        # Suppression des prints d'intent et de nombre d'emails trouv√©s
        emails = []
        if intent == "IMPORTANT":
            emails = fetch_important_emails(user_id)
        elif intent == "SPECIFIC_DATE" and specific_date:
            emails = fetch_emails_by_specific_date(user_id, specific_date)
        elif intent == "TEMPORAL":
            emails = fetch_emails_by_date(user_id, period)
        elif intent == "SEMANTIC":
            emails = search_similar_emails(question, user_id)
        else:  # HYBRID
            temporal_emails = []
            if period:
                temporal_emails = fetch_emails_by_date(user_id, period)
            elif specific_date:
                temporal_emails = fetch_emails_by_specific_date(user_id, specific_date)
            semantic_emails = search_similar_emails(question, user_id)
            emails = temporal_emails + semantic_emails

        # ==================== ANALYZE SENTIMENTS ====================
        # Analyser les sentiments pour les premiers emails (pour performance)
        if emails:
            emails = batch_analyze_sentiments(emails[:10])  # Analyser max 10 emails
        
        # Sauvegarder pour follow-ups
        conv.set_emails(emails)

        # ==================== GENERATE RESPONSE ====================
        context = format_context(emails, include_sentiment=True)
        answer = ask_openai(question, context, emails)

        print(f"\nü§ñ Mini-Mindy:\n{answer}\n")
# ---------------- MAIN ----------------

def main():
    try:
        conn = get_db_connection()
        conn.close()
        print("‚úÖ PostgreSQL OK")
    except Exception as e:
        print(f"‚ùå PostgreSQL ERROR: {e}")
        return

    chat_loop(USER_EMAIL)

if __name__ == "__main__":
    main()